{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Decision Trees Learn to Make Decisions\n",
    "+ To understand how decision Trees Work, the concept of entropy\n",
    "\n",
    "Information entropy is the average rate at which information is produced by a stochastic source of data.\n",
    "\n",
    "The measure of information entropy associated with each possible data value is the negative logarithm of the probability mass function for the value:\n",
    "+ for a single Class\n",
    "\n",
    "    ent = -p*log(p) \n",
    "    \n",
    "+ sum for all Classes \n",
    "\n",
    " S = − ∑ -p*log(p) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define a entropy function for a single binary class  (0 /1 ) outcome\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_entropy(p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -p * np.log2(p)\n",
    " \n",
    "\n",
    "def get_homogeneity(x):\n",
    "    n = len(x)\n",
    "    counts = Counter(x).most_common()\n",
    "    p = counts[0][1]/n\n",
    "    return get_entropy(p) + get_entropy(1-p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore How Entropy works on different\n",
    "Entropy is measure between zero and one that measures how mix a variable is.\n",
    "+ contast variables have a entropy of zero\n",
    "+ 50/50 mix has the highest entrop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy all ones 0.0\n",
      " all zeros 0.0\n",
      "half ones and zeros 1.0\n",
      "Mostly zeros 0.8112781244591328\n",
      "Mostly Ones 0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "# Contant Distrobutions \n",
    "print('entropy all ones', get_homogeneity(np.ones(100)))\n",
    "# Contant Distrobutions \n",
    "print(' all zeros', get_homogeneity(np.zeros(100)))\n",
    "print('half ones and zeros',get_homogeneity([0,1] * 100))\n",
    "print('Mostly zeros', get_homogeneity([0, 0, 0, 1] * 100 )    )                        \n",
    "print('Mostly Ones', get_homogeneity([1, 1 ,0, 1] * 100 )    )                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain is the Difference in Entropy of a Given Variable before and after a split\n",
    "This creates some data with p(y|x=1) = .25 and p(y|x=2) = .75\n",
    "\n",
    "+ This creates a function to estimate information gain, using difference in homogeneity for each value, for y given x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_gain(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "    counts = Counter(x).most_common()\n",
    "    h = get_homogeneity(y)\n",
    "    output = {}\n",
    "    for c in counts:\n",
    "        h_after =  get_homogeneity(y[x == c[0]])\n",
    "        info_gain = h -  h_after\n",
    "        output.update({c[0]:info_gain})\n",
    "    return output\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.1431558784658321, 2: -0.04556599707503506}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import u as pd\n",
    "x =  [1,1,1,1,2,2,2,2]\n",
    "y = [0,0,0,1, 0,0,1,1]\n",
    "get_information_gain(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information_gain_weighted(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "    counts = Counter(x).most_common()\n",
    "    h = get_homogeneity(y)\n",
    "    output = {}\n",
    "    for c in counts:\n",
    "        h_after =  get_homogeneity(y[x == c[0]])\n",
    "        info_gain = h -  h_after\n",
    "        output.update({c[0]:info_gain})\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Impurity \n",
    "An Alernate way to determin splits is to use Gini Imputiry gain\n",
    "+ Gini Imputurity is as follows\n",
    "\n",
    "\n",
    "G(k) =  Σ P(i) * (1 - P(i))\n",
    "       i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impurity(x):\n",
    "    counts = Counter(x).most_common() \n",
    "    n = len(x)\n",
    "    if len(counts) == 1:\n",
    "        p = counts[0][1]/n\n",
    "        return p * (1-p)  +  (1-p) * (1 - (1- p))\n",
    "    else:\n",
    "        output= []\n",
    "        for c in counts:\n",
    "            p = c[1]/n\n",
    "            output.append(p * (1-p) )\n",
    "    return sum(output)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all zeros 0.0\n",
      "half ones and zeros 0.5\n",
      "Mostly zeros 0.375\n",
      "Mostly Ones 0.375\n"
     ]
    }
   ],
   "source": [
    "print(' all zeros', get_impurity(np.zeros(100)))\n",
    "print('half ones and zeros',get_impurity([0,1] * 100))\n",
    "print('Mostly zeros', get_impurity([0, 0, 0, 1] * 100 )    )                        \n",
    "print('Mostly Ones', get_impurity([1, 1 ,0, 1] * 100 )    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gini_gain(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "    counts = Counter(x).most_common()\n",
    "    g = get_impurity(y)\n",
    "    output = {}\n",
    "    for c in counts:\n",
    "        g_after =  get_impurity(y[x == c[0]])\n",
    "        gini_gain = g -  g_after\n",
    "        output.update({c[0]:gini_gain })\n",
    "    return output\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.09375, 2: -0.03125}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x =  [1,1,1,1,2,2,2,2]\n",
    "y = [0,0,0,1, 0,0,1,1]\n",
    "get_gini_gain(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
