{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras General Adversarial Networks (GANS)\n",
    "This tutorial is on how to create a General Adversarial Network Based on a auto encoder to generate simulated data. This pariticular work as adapted from:\n",
    "\n",
    "https://github.com/eriklindernoren/Keras-GAN#adversarial-autoencoder\n",
    "\n",
    "This essentially builds a very basic GAN using only feedforward neural networks, and no complex layers\n",
    "\n",
    "\n",
    "#### Components of a Gan\n",
    "\n",
    "###### Generator\n",
    "+ takes random data as input\n",
    "+ predicts output that looks like our training data\n",
    "+ trainable weights\n",
    "+ Not Training Seperately, training inside stacked model\n",
    "\n",
    "###### Discriminator\n",
    "+ takes real and fake data combined in one array\n",
    "+ trains against [0,1] fake vs real labels\n",
    "\n",
    "###### Stacked Generator and Discriminator\n",
    "+ Generator + Discriminator (with the weights set to be no trainable ie frozen)\n",
    "\n",
    "##### Create Data Function\n",
    "+ takes in real data, generator\n",
    "+ returns real_data, fake_data of the same size and shape\n",
    "\n",
    "##### Training Function\n",
    "+ takes in real_data, discriminator, stacked model\n",
    "+ During Each Epoc \n",
    "    + trains the distriminator on a 50/50 mix of real and fake images against [0,1] labels\n",
    "    + trains stacked model with disciminator wieghts frozed on input noise, against an array of all 1s\\\n",
    "        + this force the generator part of the stacked model to improve it's generation ablity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\Lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "# base logger setup, to standardize logging across classes\n",
    "try:\n",
    "    logger.debug('testing logger')\n",
    "except:\n",
    "    name = 'GANs'\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data \n",
    "For this experiment, data from sklearn's Boston Housing is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data \n",
    "X_train = load_boston()['data']\n",
    "feature_names = load_boston()['feature_names']\n",
    "# normalizes the data\n",
    "scaler = StandardScaler().fit(X_train )\n",
    "X_train = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Setup\n",
    "Generator is a feed forward neural network with one hidden layer.  The output layer has the same number of nodes as the real data has columns.  Keep in mind this will not be trained on it's own, but will be stacked with the discriminator\n",
    "\n",
    "+ n_real_inputs : int number of columns on the input data\n",
    "+ n_hidden_nodes : int number of nodes in the generator's hidden layer\n",
    "+ n_fake_inputs : int size of the array of random data used as input to the generator\n",
    "\n",
    "Array of Noise In -> Array of Fake Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                78        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 143\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_real_inputs = 13\n",
    "n_hidden_nodes = 5\n",
    "n_fake_inputs = 10\n",
    "\n",
    "# create a function that returns agenerator\n",
    "def create_generator(n_real_inputs, n_hidden_nodes, n_fake_inputs):\n",
    "    inputs = Input(shape=[n_fake_inputs])\n",
    "    dense_layer0 = Dense(n_hidden_nodes, kernel_initializer='glorot_normal')(inputs)\n",
    "    batch_norm_layer0 = BatchNormalization()(dense_layer0)\n",
    "    activation_layer0 = Activation('relu')(batch_norm_layer0)\n",
    "    dense_layer1 =  Dense(n_real_inputs, kernel_initializer='glorot_normal')(activation_layer0) \n",
    "    outputs = Activation('sigmoid')(dense_layer1)\n",
    "    generator = Model(inputs, outputs)\n",
    "    generator.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return generator\n",
    "\n",
    "generator = create_generator(n_real_inputs = 13, n_hidden_nodes = 5, n_fake_inputs = 10)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48387054, 0.51035076, 0.44514462, 0.48686144, 0.48740128,\n",
       "        0.6040142 , 0.44040295, 0.5304882 , 0.5187814 , 0.48172677,\n",
       "        0.59508747, 0.6323703 , 0.5526812 ],\n",
       "       [0.4469352 , 0.48444942, 0.3489605 , 0.48228285, 0.5327607 ,\n",
       "        0.82372767, 0.25842804, 0.583084  , 0.5310224 , 0.50137466,\n",
       "        0.7568576 , 0.85362273, 0.6785073 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rns a test of the generator\n",
    "test = np.random.normal(size=(2, 10))\n",
    "generator.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Setup\n",
    "The discriminator is a feedforeward nerual network with one hidden layer and drop out\n",
    "\n",
    "+ n_real_inputs : int number of columns on the input data\n",
    "+ n_hidden_nodes : int number of nodes in the generator's hidden layer\n",
    "+ dropout_rate float (probablity at which nodes of the hidden layer randomly are set to zero)\n",
    "\n",
    "Array of Real and Fake Data,  Arrray [0,1] labels in -> Probality of real or fake out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 82\n",
      "Trainable params: 82\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator(n_real_inputs, n_hidden_nodes, dropout_rate):\n",
    "    inputs = Input(shape=[n_real_inputs])\n",
    "    dense_layer0 = Dense(n_hidden_nodes, kernel_initializer='glorot_normal')(inputs)\n",
    "    activation_layer0 = Activation('relu')(dense_layer0)\n",
    "    drop0 = Dropout(dropout_rate)(activation_layer0)\n",
    "    dense_layer1 =  Dense(2, kernel_initializer='glorot_normal')(drop0) \n",
    "    outputs = Activation('softmax')(dense_layer1)\n",
    "    discriminator  = Model(inputs, outputs)\n",
    "    discriminator.compile(loss='sparse_categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "    return discriminator\n",
    "discriminator = create_discriminator(n_real_inputs, n_hidden_nodes=5,dropout_rate=.1 )\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Stacking \n",
    "generator and discriminator are stacked to create one model\n",
    "+ In the model the Discriminator Model is frozen so that error can backpropigate to the generator\n",
    "+ The array of noise is paried with an array of [1]s.  Since the discrinator is learning sort out fakes, will force the generator in improve it's ability to make them\n",
    "\n",
    "Array of Noise, Arrray [1] labels in -> Conversion to Fake Data -> Probality of real or fake out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 13)                153       \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 82\n",
      "Non-trainable params: 153\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a stacked version of the model with the generator wieghts frozen\n",
    "def create_stacked_model(generator, discriminator):\n",
    "    stacked_model = Sequential()\n",
    "    generator.trainable = False\n",
    "    stacked_model.add(generator)\n",
    "    stacked_model.add(discriminator)\n",
    "    stacked_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return stacked_model\n",
    "\n",
    "stacked_model = create_stacked_model(generator, discriminator)\n",
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Data Function\n",
    "This function takes real data and a generator, and returns array of real data and an array of fake data.  The real data is randomly select to get the batch size correcly.  Each batch is half real and half fake data\n",
    "\n",
    "+ X_train: real data input\n",
    "+ generator Keras Model\n",
    "+ batch: int size of the arrays return (num_rows)\n",
    "\n",
    "\n",
    "real_data, generator in -> real_data, fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training functions\n",
    "def create_training_data(X_train, generator, batch=10):\n",
    "    n_obs, n_inputs = X_train.shape\n",
    "    half_batch = int(batch/2)\n",
    "    n_fake_inputs = generator.get_input_shape_at(0)[1]\n",
    "    # randomly sample real data \n",
    "    index =  np.random.randint(0, n_obs, half_batch)\n",
    "    real_data = X_train[index,:]\n",
    "    # generate fake data \n",
    "    noise = np.random.normal(0, 1, (half_batch, n_fake_inputs))\n",
    "    fake_data =  generator.predict(noise)\n",
    "    return real_data, fake_data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Training Function\n",
    "+ X_train: training array\n",
    "+ generator: Keras Generator Model\n",
    "+ stacked_model:  Keras Generator stacked with Discriminator (discriminator weights frozen)\n",
    "+ epochs: int number of batches  \n",
    "+ batch: int number of rows per batch, (half real and half fake data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-04 08:43:04,247 - GANs - INFO - epoch:0/10, disc_loss: [0.7689241, 0.659], gen_loss:0.9203584790229797\n",
      "2019-10-04 08:43:04,284 - GANs - INFO - epoch:1/10, disc_loss: [0.8061289, 0.674], gen_loss:0.9177113175392151\n",
      "2019-10-04 08:43:04,320 - GANs - INFO - epoch:2/10, disc_loss: [0.8111212, 0.638], gen_loss:0.9144372344017029\n",
      "2019-10-04 08:43:04,355 - GANs - INFO - epoch:3/10, disc_loss: [0.7906476, 0.656], gen_loss:0.9099361896514893\n",
      "2019-10-04 08:43:04,390 - GANs - INFO - epoch:4/10, disc_loss: [0.77769876, 0.664], gen_loss:0.9106239676475525\n",
      "2019-10-04 08:43:04,425 - GANs - INFO - epoch:5/10, disc_loss: [0.7969023, 0.654], gen_loss:0.8984869122505188\n",
      "2019-10-04 08:43:04,460 - GANs - INFO - epoch:6/10, disc_loss: [0.7496962, 0.663], gen_loss:0.9002196788787842\n",
      "2019-10-04 08:43:04,495 - GANs - INFO - epoch:7/10, disc_loss: [0.79726297, 0.665], gen_loss:0.8940260410308838\n",
      "2019-10-04 08:43:04,529 - GANs - INFO - epoch:8/10, disc_loss: [0.7813691, 0.67], gen_loss:0.8821180462837219\n",
      "2019-10-04 08:43:04,564 - GANs - INFO - epoch:9/10, disc_loss: [0.7602829, 0.661], gen_loss:0.8819143176078796\n"
     ]
    }
   ],
   "source": [
    "def training(X_train, generator, discriminator, epochs=10, batch=10):\n",
    "    # create the stacked model\n",
    "    stacked_model = create_stacked_model(generator, discriminator)\n",
    "    # get the input data shape\n",
    "    n_obs, n_inputs = X_train.shape\n",
    "    half_batch = int(batch/2)\n",
    "    n_fake_inputs = generator.get_input_shape_at(0)[1]\n",
    "    for e in range(epochs):\n",
    "        real_data, fake_data = create_training_data(X_train, generator, batch)\n",
    "        combined_data = np.concatenate((real_data, fake_data))\n",
    "        real_labels = np.ones(half_batch)\n",
    "        fake_labels = np.zeros(half_batch)\n",
    "        combined_labels = np.append(real_labels, fake_labels)\n",
    "        \n",
    "        # discriminator loss \n",
    "        disc_loss = discriminator.train_on_batch(combined_data ,combined_labels)\n",
    "        \n",
    "        # create noise and labels of 1,\n",
    "        noise =  np.random.normal(0, 1, (batch, n_fake_inputs))\n",
    "        y_mislabled =  np.ones((batch))\n",
    "        \n",
    "        # genertor loss \n",
    "        gen_loss = stacked_model.train_on_batch(x=noise,y=y_mislabled)\n",
    "        logger.info('epoch:{0}/{1}, disc_loss: {2}, gen_loss:{3}'.format(e, epochs, disc_loss, gen_loss))\n",
    "\n",
    "    generator = stacked_model.layers[0]\n",
    "    discriminator = stacked_model.layers[1]\n",
    "    return generator, discriminator\n",
    "\n",
    "generator, discriminator  = training(X_train, generator, discriminator,  epochs=10, batch=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Fake Data \n",
    "using random normals to generate face data, this essentialy reverses the scaler to get the data back on the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.630709</td>\n",
       "      <td>25.205938</td>\n",
       "      <td>13.705052</td>\n",
       "      <td>0.127833</td>\n",
       "      <td>0.615989</td>\n",
       "      <td>6.729080</td>\n",
       "      <td>86.306015</td>\n",
       "      <td>4.993907</td>\n",
       "      <td>14.583076</td>\n",
       "      <td>503.467377</td>\n",
       "      <td>19.134132</td>\n",
       "      <td>406.529541</td>\n",
       "      <td>17.683327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.482731</td>\n",
       "      <td>25.808048</td>\n",
       "      <td>13.730895</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>0.620942</td>\n",
       "      <td>6.716838</td>\n",
       "      <td>84.361420</td>\n",
       "      <td>4.945702</td>\n",
       "      <td>14.397435</td>\n",
       "      <td>515.505920</td>\n",
       "      <td>19.137049</td>\n",
       "      <td>403.286377</td>\n",
       "      <td>17.494619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.869923</td>\n",
       "      <td>24.657532</td>\n",
       "      <td>13.952588</td>\n",
       "      <td>0.160760</td>\n",
       "      <td>0.621343</td>\n",
       "      <td>6.720174</td>\n",
       "      <td>82.104767</td>\n",
       "      <td>4.911867</td>\n",
       "      <td>14.150250</td>\n",
       "      <td>512.250427</td>\n",
       "      <td>19.320797</td>\n",
       "      <td>406.522400</td>\n",
       "      <td>17.175816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.590015</td>\n",
       "      <td>26.893044</td>\n",
       "      <td>13.610885</td>\n",
       "      <td>0.140755</td>\n",
       "      <td>0.627422</td>\n",
       "      <td>6.718511</td>\n",
       "      <td>82.590912</td>\n",
       "      <td>4.913502</td>\n",
       "      <td>14.294861</td>\n",
       "      <td>530.572998</td>\n",
       "      <td>19.074656</td>\n",
       "      <td>400.094849</td>\n",
       "      <td>17.509432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM         ZN      INDUS      CHAS       NOX        RM        AGE  \\\n",
       "0  9.630709  25.205938  13.705052  0.127833  0.615989  6.729080  86.306015   \n",
       "1  9.482731  25.808048  13.730895  0.138355  0.620942  6.716838  84.361420   \n",
       "2  8.869923  24.657532  13.952588  0.160760  0.621343  6.720174  82.104767   \n",
       "3  9.590015  26.893044  13.610885  0.140755  0.627422  6.718511  82.590912   \n",
       "\n",
       "        DIS        RAD         TAX    PTRATIO           B      LSTAT  \n",
       "0  4.993907  14.583076  503.467377  19.134132  406.529541  17.683327  \n",
       "1  4.945702  14.397435  515.505920  19.137049  403.286377  17.494619  \n",
       "2  4.911867  14.150250  512.250427  19.320797  406.522400  17.175816  \n",
       "3  4.913502  14.294861  530.572998  19.074656  400.094849  17.509432  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make some fake data\n",
    "def make_fake_data(batch, generator, scaler):\n",
    "    n_fake_inputs =  generator.get_weights()[0].shape[0]\n",
    "    noise =  np.random.normal(0, 1, (batch, n_fake_inputs))\n",
    "    fake_data = generator.predict(noise)\n",
    "    fake_data_unscaled = scaler.inverse_transform(fake_data)\n",
    "    return fake_data_unscaled \n",
    "print('FAKE :')\n",
    "pd.DataFrame(make_fake_data(batch=4, generator=generator, scaler=scaler), columns=feature_names)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('REAL :')\n",
    "test_data = load_boston()['data'] \n",
    "pd.DataFrame(test_data[0:4,:], columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking for Fake Data or Outliers\n",
    "The discriminator function can be used to detect outliers or look for fake data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735093</td>\n",
       "      <td>0.264907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407069</td>\n",
       "      <td>0.592931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507168</td>\n",
       "      <td>0.492832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543324</td>\n",
       "      <td>0.456676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.556500</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fake      real\n",
       "0  0.735093  0.264907\n",
       "1  0.407069  0.592931\n",
       "2  0.507168  0.492832\n",
       "3  0.543324  0.456676\n",
       "4  0.556500  0.443500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_fake(x, dicriminator, scaler):\n",
    "    x_scaled = scaler.transform(x)\n",
    "    prob =  dicriminator.predict(x_scaled)\n",
    "    return prob\n",
    " \n",
    "pd.DataFrame(is_fake(test_data, discriminator, scaler), columns=['fake', 'real']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Models\n",
    "If you want to save the model\n",
    "and load it later for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to _model.h5\n"
     ]
    }
   ],
   "source": [
    "path = \"_model.h5\"\n",
    "model = generator\n",
    "# serialize weights to HDF5\n",
    "model.save(path,  overwrite=True)\n",
    "print(\"Saved model to {}\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                78        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 143\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.6574674e+00, 3.0479498e+01, 1.2478597e+01, 1.8674630e-01,\n",
       "        6.1072046e-01, 6.8288379e+00, 7.4392029e+01, 5.0441360e+00,\n",
       "        1.4764271e+01, 5.2169354e+02, 2.0199808e+01, 4.3279443e+02,\n",
       "        1.7316753e+01],\n",
       "       [7.0966034e+00, 2.4860298e+01, 1.4669879e+01, 2.0017436e-01,\n",
       "        5.9405363e-01, 6.5576000e+00, 8.4546837e+01, 5.0787811e+00,\n",
       "        1.1993657e+01, 5.2492279e+02, 1.9207066e+01, 4.1454782e+02,\n",
       "        1.5964885e+01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_loaded = load_model(path)\n",
    "# summarize model.\n",
    "model_loaded.summary()\n",
    "make_fake_data(2, model_loaded, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup\n",
    "os.remove(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
