{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras General Adversarial Networks (GANS)\n",
    "This tutorial is on how to create a General Adversarial Network Based on a auto encoder to generate simulated data. This pariticular work as adapted from:\n",
    "\n",
    "https://github.com/eriklindernoren/Keras-GAN#adversarial-autoencoder\n",
    "\n",
    "This essentially builds a very basic GAN using only feedforward neural networks, and no complex layers\n",
    "\n",
    "\n",
    "#### Components of a Gan\n",
    "\n",
    "###### Generator\n",
    "+ takes random data as input\n",
    "+ predicts output that looks like our training data\n",
    "+ trainable weights\n",
    "+ Not Training Seperately, training inside stacked model\n",
    "\n",
    "###### Discriminator\n",
    "+ takes real and fake data combined in one array\n",
    "+ trains against [0,1] fake vs real labels\n",
    "\n",
    "###### Stacked Generator and Discriminator\n",
    "+ Generator + Discriminator (with the weights set to be no trainable ie frozen)\n",
    "\n",
    "##### Create Data Function\n",
    "+ takes in real data, generator\n",
    "+ returns real_data, fake_data of the same size and shape\n",
    "\n",
    "##### Training Function\n",
    "+ takes in real_data, discriminator, stacked model\n",
    "+ During Each Epoc \n",
    "    + trains the distriminator on a 50/50 mix of real and fake images against [0,1] labels\n",
    "    + trains stacked model with disciminator wieghts frozed on input noise, against an array of all 1s\\\n",
    "        + this force the generator part of the stacked model to improve it's generation ablity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "# base logger setup, to standardize logging across classes\n",
    "try:\n",
    "    logger.debug('testing logger')\n",
    "except:\n",
    "    name = 'GANs'\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data \n",
    "For this experiment, data from sklearn's Boston Housing is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data \n",
    "X_train = load_boston()['data']\n",
    "feature_names = load_boston()['feature_names']\n",
    "# normalizes the data\n",
    "scaler = StandardScaler().fit(X_train )\n",
    "X_train = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Setup\n",
    "Generator is a feed forward neural network with one hidden layer.  The output layer has the same number of nodes as the real data has columns.  Keep in mind this will not be trained on it's own, but will be stacked with the discriminator\n",
    "\n",
    "+ n_real_inputs : int number of columns on the input data\n",
    "+ n_hidden_nodes : int number of nodes in the generator's hidden layer\n",
    "+ n_fake_inputs : int size of the array of random data used as input to the generator\n",
    "\n",
    "Array of Noise In -> Array of Fake Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                78        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 143\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_real_inputs = 13\n",
    "n_hidden_nodes = 5\n",
    "n_fake_inputs = 10\n",
    "\n",
    "# create a function that returns agenerator\n",
    "def create_generator(n_real_inputs, n_hidden_nodes, n_fake_inputs):\n",
    "    inputs = Input(shape=[n_fake_inputs])\n",
    "    dense_layer0 = Dense(n_hidden_nodes, kernel_initializer='glorot_normal')(inputs)\n",
    "    batch_norm_layer0 = BatchNormalization()(dense_layer0)\n",
    "    activation_layer0 = Activation('relu')(batch_norm_layer0)\n",
    "    dense_layer1 =  Dense(n_real_inputs, kernel_initializer='glorot_normal')(activation_layer0) \n",
    "    outputs = Activation('sigmoid')(dense_layer1)\n",
    "    generator = Model(inputs, outputs)\n",
    "    generator.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return generator\n",
    "\n",
    "generator = create_generator(n_real_inputs = 13, n_hidden_nodes = 5, n_fake_inputs = 10)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56643915, 0.49242553, 0.5576671 , 0.6748881 , 0.6383636 ,\n",
       "        0.4239404 , 0.43823797, 0.31251425, 0.54140085, 0.68441135,\n",
       "        0.196712  , 0.21001649, 0.49259657],\n",
       "       [0.5253104 , 0.5042248 , 0.5017169 , 0.54026073, 0.5263095 ,\n",
       "        0.48517618, 0.49078184, 0.4439832 , 0.50967795, 0.54273593,\n",
       "        0.42076752, 0.41966155, 0.497997  ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rns a test of the generator\n",
    "test = np.random.normal(size=(2, 10))\n",
    "generator.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Setup\n",
    "The discriminator is a feedforeward nerual network with one hidden layer and drop out\n",
    "\n",
    "+ n_real_inputs : int number of columns on the input data\n",
    "+ n_hidden_nodes : int number of nodes in the generator's hidden layer\n",
    "+ dropout_rate float (probablity at which nodes of the hidden layer randomly are set to zero)\n",
    "\n",
    "Array of Real and Fake Data,  Arrray [0,1] labels in -> Probality of real or fake out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 82\n",
      "Trainable params: 82\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator(n_real_inputs, n_hidden_nodes, dropout_rate):\n",
    "    inputs = Input(shape=[n_real_inputs])\n",
    "    dense_layer0 = Dense(n_hidden_nodes, kernel_initializer='glorot_normal')(inputs)\n",
    "    activation_layer0 = Activation('relu')(dense_layer0)\n",
    "    drop0 = Dropout(dropout_rate)(activation_layer0)\n",
    "    dense_layer1 =  Dense(2, kernel_initializer='glorot_normal')(drop0) \n",
    "    outputs = Activation('softmax')(dense_layer1)\n",
    "    discriminator  = Model(inputs, outputs)\n",
    "    discriminator.compile(loss='sparse_categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "    return discriminator\n",
    "discriminator = create_discriminator(n_real_inputs, n_hidden_nodes=5,dropout_rate=.1 )\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Stacking \n",
    "generator and discriminator are stacked to create one model\n",
    "+ In the model the Discriminator Model is frozen so that error can backpropigate to the generator\n",
    "+ The array of noise is paried with an array of [1]s.  Since the discrinator is learning sort out fakes, will force the generator in improve it's ability to make them\n",
    "\n",
    "Array of Noise, Arrray [1] labels in -> Conversion to Fake Data -> Probality of real or fake out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 13)                153       \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 82\n",
      "Non-trainable params: 153\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a stacked version of the model with the generator wieghts frozen\n",
    "def create_stacked_model(generator, discriminator):\n",
    "    stacked_model = Sequential()\n",
    "    generator.trainable = False\n",
    "    stacked_model.add(generator)\n",
    "    stacked_model.add(discriminator)\n",
    "    stacked_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return stacked_model\n",
    "\n",
    "stacked_model = create_stacked_model(generator, discriminator)\n",
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Data Function\n",
    "This function takes real data and a generator, and returns array of real data and an array of fake data.  The real data is randomly select to get the batch size correcly.  Each batch is half real and half fake data\n",
    "\n",
    "+ X_train: real data input\n",
    "+ generator Keras Model\n",
    "+ batch: int size of the arrays return (num_rows)\n",
    "\n",
    "\n",
    "real_data, generator in -> real_data, fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training functions\n",
    "def create_training_data(X_train, generator, batch=10):\n",
    "    n_obs, n_inputs = X_train.shape\n",
    "    half_batch = int(batch/2)\n",
    "    n_fake_inputs = generator.get_input_shape_at(0)[1]\n",
    "    # randomly sample real data \n",
    "    index =  np.random.randint(0, n_obs, half_batch)\n",
    "    real_data = X_train[index,:]\n",
    "    # generate fake data \n",
    "    noise = np.random.normal(0, 1, (half_batch, n_fake_inputs))\n",
    "    fake_data =  generator.predict(noise)\n",
    "    return real_data, fake_data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Training Function\n",
    "+ X_train: training array\n",
    "+ generator: Keras Generator Model\n",
    "+ stacked_model:  Keras Generator stacked with Discriminator (discriminator weights frozen)\n",
    "+ epochs: int number of batches  \n",
    "+ batch: int number of rows per batch, (half real and half fake data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-03 14:27:08,620 - GANs - INFO - epoch:0/10, disc_loss: [0.61967427, 0.744], gen_loss:1.3066082000732422\n",
      "2019-10-03 14:27:08,656 - GANs - INFO - epoch:1/10, disc_loss: [0.621907, 0.76], gen_loss:1.3072524070739746\n",
      "2019-10-03 14:27:08,693 - GANs - INFO - epoch:2/10, disc_loss: [0.6206468, 0.756], gen_loss:1.287769079208374\n",
      "2019-10-03 14:27:08,729 - GANs - INFO - epoch:3/10, disc_loss: [0.5974836, 0.763], gen_loss:1.2801730632781982\n",
      "2019-10-03 14:27:08,765 - GANs - INFO - epoch:4/10, disc_loss: [0.6123271, 0.75], gen_loss:1.2691081762313843\n",
      "2019-10-03 14:27:08,800 - GANs - INFO - epoch:5/10, disc_loss: [0.61043376, 0.754], gen_loss:1.2368003129959106\n",
      "2019-10-03 14:27:08,836 - GANs - INFO - epoch:6/10, disc_loss: [0.5983659, 0.754], gen_loss:1.2508504390716553\n",
      "2019-10-03 14:27:08,873 - GANs - INFO - epoch:7/10, disc_loss: [0.60950464, 0.756], gen_loss:1.2318276166915894\n",
      "2019-10-03 14:27:08,909 - GANs - INFO - epoch:8/10, disc_loss: [0.62912416, 0.742], gen_loss:1.2034859657287598\n",
      "2019-10-03 14:27:08,945 - GANs - INFO - epoch:9/10, disc_loss: [0.59086406, 0.768], gen_loss:1.2104458808898926\n"
     ]
    }
   ],
   "source": [
    "def training(X_train, generator, discriminator, epochs=10, batch=10):\n",
    "    # create the stacked model\n",
    "    stacked_model = create_stacked_model(generator, discriminator)\n",
    "    # get the input data shape\n",
    "    n_obs, n_inputs = X_train.shape\n",
    "    half_batch = int(batch/2)\n",
    "    n_fake_inputs = generator.get_input_shape_at(0)[1]\n",
    "    for e in range(epochs):\n",
    "        real_data, fake_data = create_training_data(X_train, generator, batch)\n",
    "        combined_data = np.concatenate((real_data, fake_data))\n",
    "        real_labels = np.ones(half_batch)\n",
    "        fake_labels = np.zeros(half_batch)\n",
    "        combined_labels = np.append(real_labels, fake_labels)\n",
    "        \n",
    "        # discriminator loss \n",
    "        disc_loss = discriminator.train_on_batch(combined_data ,combined_labels)\n",
    "        \n",
    "        # create noise and labels of 1,\n",
    "        noise =  np.random.normal(0, 1, (batch, n_fake_inputs))\n",
    "        y_mislabled =  np.ones((batch))\n",
    "        \n",
    "        # genertor loss \n",
    "        gen_loss = stacked_model.train_on_batch(x=noise,y=y_mislabled)\n",
    "        logger.info('epoch:{0}/{1}, disc_loss: {2}, gen_loss:{3}'.format(e, epochs, disc_loss, gen_loss))\n",
    "\n",
    "    generator = stacked_model.layers[0]\n",
    "    discriminator = stacked_model.layers[1]\n",
    "    return generator, discriminator\n",
    "\n",
    "generator, discriminator  = training(X_train, generator, discriminator,  epochs=10, batch=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Fake Data \n",
    "using random normals to generate face data, this essentialy reverses the scaler to get the data back on the original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.154866</td>\n",
       "      <td>21.322029</td>\n",
       "      <td>15.625684</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.627697</td>\n",
       "      <td>6.590303</td>\n",
       "      <td>80.261192</td>\n",
       "      <td>4.942539</td>\n",
       "      <td>14.035790</td>\n",
       "      <td>509.117096</td>\n",
       "      <td>19.204794</td>\n",
       "      <td>394.913300</td>\n",
       "      <td>16.223076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.409275</td>\n",
       "      <td>23.449846</td>\n",
       "      <td>17.518940</td>\n",
       "      <td>0.322013</td>\n",
       "      <td>0.603792</td>\n",
       "      <td>6.390985</td>\n",
       "      <td>91.540504</td>\n",
       "      <td>3.893902</td>\n",
       "      <td>10.295435</td>\n",
       "      <td>576.231201</td>\n",
       "      <td>18.457268</td>\n",
       "      <td>373.290985</td>\n",
       "      <td>15.396666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.341480</td>\n",
       "      <td>20.742504</td>\n",
       "      <td>17.268656</td>\n",
       "      <td>0.311714</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>6.466686</td>\n",
       "      <td>86.482071</td>\n",
       "      <td>4.436302</td>\n",
       "      <td>11.241587</td>\n",
       "      <td>571.005981</td>\n",
       "      <td>18.502550</td>\n",
       "      <td>396.316742</td>\n",
       "      <td>15.987784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.910044</td>\n",
       "      <td>23.013334</td>\n",
       "      <td>14.563564</td>\n",
       "      <td>0.196041</td>\n",
       "      <td>0.612577</td>\n",
       "      <td>6.635596</td>\n",
       "      <td>82.635414</td>\n",
       "      <td>4.846857</td>\n",
       "      <td>13.898733</td>\n",
       "      <td>492.422394</td>\n",
       "      <td>19.536936</td>\n",
       "      <td>402.276337</td>\n",
       "      <td>16.220064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM         ZN      INDUS      CHAS       NOX        RM        AGE  \\\n",
       "0  7.154866  21.322029  15.625684  0.220020  0.627697  6.590303  80.261192   \n",
       "1  5.409275  23.449846  17.518940  0.322013  0.603792  6.390985  91.540504   \n",
       "2  5.341480  20.742504  17.268656  0.311714  0.617764  6.466686  86.482071   \n",
       "3  7.910044  23.013334  14.563564  0.196041  0.612577  6.635596  82.635414   \n",
       "\n",
       "        DIS        RAD         TAX    PTRATIO           B      LSTAT  \n",
       "0  4.942539  14.035790  509.117096  19.204794  394.913300  16.223076  \n",
       "1  3.893902  10.295435  576.231201  18.457268  373.290985  15.396666  \n",
       "2  4.436302  11.241587  571.005981  18.502550  396.316742  15.987784  \n",
       "3  4.846857  13.898733  492.422394  19.536936  402.276337  16.220064  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make some fake data\n",
    "def make_fake_data(batch, generator, scaler):\n",
    "    n_fake_inputs =  generator.get_weights()[0].shape[0]\n",
    "    noise =  np.random.normal(0, 1, (batch, n_fake_inputs))\n",
    "    fake_data = generator.predict(noise)\n",
    "    fake_data_unscaled = scaler.inverse_transform(fake_data)\n",
    "    return fake_data_unscaled \n",
    "print('FAKE :')\n",
    "pd.DataFrame(make_fake_data(batch=4, generator=generator, scaler=scaler), columns=feature_names)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('REAL :')\n",
    "test_data = load_boston()['data'] \n",
    "pd.DataFrame(test_data[0:4,:], columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking for Fake Data or Outliers\n",
    "The discriminator function can be used to detect outliers or look for fake data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547792</td>\n",
       "      <td>0.452208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184778</td>\n",
       "      <td>0.815222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334692</td>\n",
       "      <td>0.665308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217157</td>\n",
       "      <td>0.782842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.189465</td>\n",
       "      <td>0.810535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fake      real\n",
       "0  0.547792  0.452208\n",
       "1  0.184778  0.815222\n",
       "2  0.334692  0.665308\n",
       "3  0.217157  0.782842\n",
       "4  0.189465  0.810535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_fake(x, dicriminator, scaler):\n",
    "    x_scaled = scaler.transform(x)\n",
    "    prob =  dicriminator.predict(x_scaled)\n",
    "    return prob\n",
    " \n",
    "pd.DataFrame(is_fake(test_data, discriminator, scaler), columns=['fake', 'real']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Models\n",
    "If you want to save the model\n",
    "and load it later for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to _model.h5\n"
     ]
    }
   ],
   "source": [
    "path = \"_model.h5\"\n",
    "model = generator\n",
    "# serialize weights to HDF5\n",
    "model.save(path,  overwrite=True)\n",
    "print(\"Saved model to {}\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                78        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 143\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.5817661e+00, 2.2790003e+01, 1.4636750e+01, 2.2389206e-01,\n",
       "        6.1003739e-01, 6.6523571e+00, 8.4787682e+01, 4.7551684e+00,\n",
       "        1.3559386e+01, 5.0940768e+02, 1.9177650e+01, 4.0985922e+02,\n",
       "        1.6514050e+01],\n",
       "       [7.5191550e+00, 2.2815746e+01, 1.4599019e+01, 1.9653280e-01,\n",
       "        6.1633396e-01, 6.6510787e+00, 8.2009132e+01, 4.9424906e+00,\n",
       "        1.4604495e+01, 4.8578214e+02, 1.9499296e+01, 4.0600519e+02,\n",
       "        1.6175621e+01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_loaded = load_model(path)\n",
    "# summarize model.\n",
    "model_loaded.summary()\n",
    "make_fake_data(2, model_loaded, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup\n",
    "os.remove(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
