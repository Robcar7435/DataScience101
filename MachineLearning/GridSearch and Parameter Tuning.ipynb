{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HyperParameter Searching\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "data.head(10)\n",
    "\n",
    "# setup method for missing data using a median imputer for age and fair\n",
    "numeric_features = ['Age', 'Fare', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "     ('scaler', StandardScaler())])\n",
    "# setup one hot enoding for catagorical features\n",
    "categorical_features = [ 'Sex', 'Pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# combine numeric and catagorical transformation into one column transformer object\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# drop rows where survived is unknown\n",
    "y = data['Survived']\n",
    "X = pipe.fit_transform(data)\n",
    "\n",
    "# normalizes the feature names\n",
    "feature_names = numeric_features +  pipe.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names().tolist()\n",
    "feature_names = list(map(lambda x: x.replace('x0',categorical_features[0]), feature_names))\n",
    "feature_names = list(map(lambda x: x.replace('x1',categorical_features[1]), feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a baseline model using CrossValidation to see what gain is made from Random Fro\n",
    "A single Decision Tree Model is used here as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "# show all the difference metrix tp \n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Best Classifier\n",
      "best accuracy score : 0.8409090909090909\n",
      "true [[456  89]\n",
      " [ 97 245]] \n",
      " predicted\n"
     ]
    }
   ],
   "source": [
    "# base line model with one Tree\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "model = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "# estimates accuracy\n",
    "scores = cross_validate(model, X, y, scoring=[scoring] , cv=10)\n",
    "best_score = np.max(scores['test_' + scoring])\n",
    "print('Random Tree Best Classifier')\n",
    "print('best {0} score : {1}'.format(scoring, best_score))\n",
    "# create predictions \n",
    "y_pred = cross_val_predict(model, X, y, cv = 10)\n",
    "print('true', confusion_matrix(y, y_pred), '\\n predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Best Classifier\n",
      "best accuracy score : 0.847457627118644\n",
      "true [[472  73]\n",
      " [104 238]] \n",
      " predicted\n"
     ]
    }
   ],
   "source": [
    "### Is randpom forest really better ?\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "scoring = 'accuracy'\n",
    "# estimates accuracy\n",
    "scores = cross_validate(model, X, y, scoring=[scoring] , cv=5)\n",
    "best_score = np.max(scores['test_' + scoring])\n",
    "print('Random Tree Best Classifier')\n",
    "print('best {0} score : {1}'.format(scoring, best_score))\n",
    "# create predictions \n",
    "y_pred = cross_val_predict(model, X, y, cv = 5)\n",
    "print('true', confusion_matrix(y, y_pred), '\\n predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': array([10, 20]), 'max_depth': [3, 4, 5], 'min_samples_split': array([2, 4]), 'min_samples_leaf': array([2, 4])}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators  = np.arange(10,30, 10)\n",
    "# Number of features to consider at every split\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [3,4,5]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = np.arange(2, 6, 2)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = np.arange(2, 6,2)\n",
    "# Method of selecting samples for training each tree\n",
    "param_grid= {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10)\n",
    "model = GridSearchCV(model, param_grid = param_grid,cv = 3,scoring=scoring, n_jobs = -1,  refit=True)\n",
    "\n",
    "model = model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tree Best Classifier on Grid Cearh \n",
      "true [[503  42]\n",
      " [ 95 247]] \n",
      " predicted\n",
      "acc: 0.8455467869222097 \n"
     ]
    }
   ],
   "source": [
    "print('Random Tree Best Classifier on Grid Cearh ')\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create predictions \n",
    "y_pred = model.predict(X)\n",
    "print('true', confusion_matrix(y, y_pred), '\\n predicted')\n",
    "print('acc: {} '.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
