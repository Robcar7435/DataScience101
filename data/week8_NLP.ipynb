{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Natural Language Processing (NLP)\n",
    "The world of nlp is very large.  This example is using a bag of words, n_gram approach, that often works well, but will typically have the problem of\n",
    "+ 'the shark ate kids'\n",
    "+ ' the kids ate shark'\n",
    "Did the kids get eaten?\n",
    "\n",
    "## NLP Work Flow\n",
    "\n",
    "+ load data\n",
    "+ split data\n",
    "+ clean text\n",
    "+ fit tokenzer\n",
    "+ transform test and training sets\n",
    "+ train model\n",
    "+ eval on training and test sets\n",
    "\n",
    "\n",
    "## Data \n",
    "+ Polirity data set, 1000 positive and 1000 negative movie reviews.\n",
    "+ Download Polarity http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "+ create a directory and move the downloaded tar.gz file to that directory\n",
    "+ run this command (linux/ mac and maybe windows)\n",
    "+ if this doesn't work withn windows, download and use 7zip to decompress the fill\n",
    "```bash\n",
    " tar xzvf review_polarity.tar.gz\n",
    "```\n",
    "\n",
    "\n",
    "## Home (for wednesday)\n",
    "Identity and download a text data set to analyze sentiment on. \n",
    "you will create a sentiment analysis model using polarity data set,\n",
    "+ data set should have at least 100 text sequences\n",
    "+ you find the top five most negative and most positive examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data \n",
    "import os\n",
    "import numpy as np\n",
    "# define a function to read in text\n",
    "def read_file_list(file_list):\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.readlines()\n",
    "            text = ' '.join(text)\n",
    "            yield text\n",
    "# get the list of file paths\n",
    "pos_dir = './data/polarity/txt_sentoken/pos'\n",
    "neg_dir = './data/polarity/txt_sentoken/neg'\n",
    "pos_files = os.listdir(pos_dir)\n",
    "neg_files = os.listdir(neg_dir)\n",
    "# data the working dir to the file paths\n",
    "pos_files = [pos_dir + '/' + f for f in pos_files if 'cv' in f]\n",
    "neg_files = [neg_dir + '/' + f for f in neg_files if 'cv' in f]\n",
    "neg_reviews = list(read_file_list(neg_files))\n",
    "pos_reviews = list(read_file_list(pos_files))\n",
    "data = pos_reviews + neg_files\n",
    "# positive 1, negative review 5\n",
    "labels = np.array([1] * len(pos_reviews) + [0] * len(neg_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Steps\n",
    "'12 cleaning this text string !'\n",
    "+ remove Symobls => '12 cleaning this text string'\n",
    "+ remove numbers => 'cleaning this text string'\n",
    "+ remove stop words => 'cleaning text string'\n",
    "+ stemming (optional) => 'clean text string'\n",
    "+ n_gram (clean text), (text string) \n",
    "+ one hot encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12211151, 0.03492696, 0.08647343, 0.        , 0.08137688,\n        0.02726012, 0.05199456, 0.08374756, 0.08280507, 0.07484688,\n        0.10545938, 0.        , 0.18417806, 0.02719272, 0.06318385,\n        0.        , 0.        , 0.        , 0.03558656, 0.        ,\n        0.09835596, 0.13596362, 0.03765698, 0.06907826, 0.07822541,\n        0.22276378, 0.07013583, 0.06671202, 0.0389553 , 0.05698207,\n        0.05887214, 0.08395969, 0.06779323, 0.03308038, 0.        ,\n        0.0378942 , 0.06489643, 0.46050558, 0.06350049, 0.17919134,\n        0.28275527, 0.03413437, 0.        , 0.        , 0.12169361,\n        0.07451761, 0.07194506, 0.        , 0.        , 0.05974279,\n        0.        , 0.        , 0.03392285, 0.034403  , 0.05604409,\n        0.3577483 , 0.0267129 , 0.02715914, 0.        , 0.09443955,\n        0.06748034, 0.        , 0.03696691, 0.        , 0.        ,\n        0.07647935, 0.07065002, 0.03680716, 0.09120778, 0.        ,\n        0.        , 0.0970598 , 0.10318682, 0.03179579, 0.        ,\n        0.03052788, 0.06072212, 0.10594642, 0.03225891, 0.38352809,\n        0.        , 0.        , 0.        , 0.        , 0.03054886,\n        0.03509627, 0.03019607, 0.        , 0.        , 0.03368838,\n        0.        , 0.06113974, 0.03680716, 0.        , 0.        ,\n        0.13697911, 0.03408121, 0.10367928, 0.0347873 , 0.12161037],\n       [0.        , 0.        , 0.02545776, 0.        , 0.21561604,\n        0.02407612, 0.1148039 , 0.04931053, 0.07313339, 0.03305236,\n        0.06209444, 0.        , 0.11618996, 0.        , 0.02790197,\n        0.03097196, 0.        , 0.        , 0.        , 0.06244899,\n        0.17373584, 0.12008299, 0.09977587, 0.        , 0.04605909,\n        0.24593104, 0.        , 0.02946001, 0.        , 0.0754898 ,\n        0.10399168, 0.12358858, 0.08981241, 0.        , 0.11993467,\n        0.03346813, 0.        , 0.2711455 , 0.        , 0.49739385,\n        0.22702662, 0.0602949 , 0.        , 0.06402426, 0.10747972,\n        0.03290695, 0.        , 0.        , 0.03305236, 0.0263824 ,\n        0.08516283, 0.05319376, 0.        , 0.06076941, 0.0494981 ,\n        0.27082549, 0.02359281, 0.02398693, 0.        , 0.        ,\n        0.0297993 , 0.        , 0.06529831, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.16110931, 0.        ,\n        0.03012396, 0.02857439, 0.25061998, 0.        , 0.        ,\n        0.08088661, 0.05362974, 0.09357181, 0.        , 0.31614965,\n        0.        , 0.03094697, 0.        , 0.        , 0.02698073,\n        0.        , 0.02666915, 0.06209444, 0.        , 0.02975356,\n        0.05505934, 0.02699929, 0.        , 0.08346817, 0.        ,\n        0.        , 0.0301005 , 0.11446184, 0.        , 0.0537031 ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# count vectorizer handels all these steps, setup some args for the count vect\n",
    "\n",
    "# setup stop work list (to remove from docs)\n",
    "stop_words = ['and', 'the', 'n', 't', 'neg']\n",
    "# setup n_gram ranges\n",
    "ngram_range = (1, 1)\n",
    "# drop words that show up 70% or more of the time\n",
    "max_df = .7\n",
    "# drop words that only show up less than 1% of the time\n",
    "min_df = .001\n",
    "max_features = 100\n",
    "# init the count ce\n",
    "c = TfidfVectorizer(stop_words=stop_words, ngram_range=ngram_range, max_df=max_df, min_df=min_df, \n",
    "                    max_features=max_features, )\n",
    "features = c.fit_transform(data)\n",
    "features = features.toarray()\n",
    "features[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver= 'lbfgs')\n",
    "model.fit(features, labels)\n",
    "preds = model.predict_proba(features)[:, 1]\n",
    "preds_labels = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      1000\n           1       1.00      1.00      1.00      1000\n\n   micro avg       1.00      1.00      1.00      2000\n   macro avg       1.00      1.00      1.00      2000\nweighted avg       1.00      1.00      1.00      2000\n\n1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(labels, preds_labels ))\n",
    "print(roc_auc_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13509313, 0.86490687],\n       [0.06810775, 0.93189225]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the system\n",
    "def predict(data):\n",
    "    features = c.transform(data).toarray()\n",
    "    preds = model.predict_proba(features)\n",
    "    return preds\n",
    "\n",
    "test = ['I hate this class, make it stop, terrivle awefull,  can not end fast enough',\n",
    " 'this class is greate I love everything about it']\n",
    "predict(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\npolarity\n"
     ]
    }
   ],
   "source": [
    "# look at features\n",
    "from matplotlib import pyplot as plt\n",
    "x = np.array(c.get_feature_names())\n",
    "y = model.coef_\n",
    "print(x[np.argmax(y)])\n",
    "print(x[np.argmin(y)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
